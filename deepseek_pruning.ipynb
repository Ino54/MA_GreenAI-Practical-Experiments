{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ino54/MA_GreenAI-Practical-Experiments/blob/main/deepseek_pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3zc_aowChLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b945a90-95e0-4d38-a593-70ff37e3807b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# =====================  Requirements =====================\n",
        "%%writefile requirements.txt\n",
        "transformers>=4.44\n",
        "accelerate>=0.33\n",
        "bitsandbytes\n",
        "datasets>=2.20\n",
        "evaluate>=0.4\n",
        "sacrebleu>=2.4\n",
        "codecarbon>=2.5,<3\n",
        "psutil\n",
        "pynvml>=12,<13\n",
        "numpy==2.0.2\n",
        "pandas==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== 0b) Install =====================\n",
        "!pip install -q -U -r requirements.txt --no-warn-conflicts\n",
        "!pip uninstall -y -q google-genai firebase-admin || true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgRa3g735Wvv",
        "outputId": "4bb88ca8-9ac1-4982-aec8-0344d384ccc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.6/517.6 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.2/291.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Drive & Ordner =====================\n",
        "import os, pathlib, shutil, time, warnings, platform\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from google.colab import drive\n",
        "MOUNT=\"/content/drive\"\n",
        "already=os.path.isdir(os.path.join(MOUNT,\"MyDrive\"))\n",
        "if not already and os.path.isdir(MOUNT) and os.listdir(MOUNT):\n",
        "    backup=f\"/content/drive_stale_{int(time.time())}\"\n",
        "    shutil.move(MOUNT, backup); os.makedirs(MOUNT, exist_ok=True)\n",
        "drive.mount(MOUNT, force_remount=(not already))\n",
        "\n",
        "project_path = \"/content/drive/MyDrive/LLM-Effizienz/4_3_Effizienzstrategien/deepseek_pruning\"\n",
        "pathlib.Path(project_path).mkdir(parents=True, exist_ok=True)\n",
        "os.chdir(project_path); print(\"Arbeitsordner:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36CyqQk65aXT",
        "outputId": "824a8579-e215-4d84-be45-f5cdd034a423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Arbeitsordner: /content/drive/MyDrive/LLM-Effizienz/4_3_Effizienzstrategien/deepseek_pruning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== 2) HF Login (optional) =====================\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "if hf_token:\n",
        "    login(hf_token); print(\"Hugging Face Login erfolgreich!\")\n",
        "else:\n",
        "    print(\"WARNUNG: Kein HF_TOKEN.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7tVWVWc5b4E",
        "outputId": "4b0e9eac-084e-402f-b02e-3cc113a38463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hugging Face Login erfolgreich!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== 3) Imports & Device =====================\n",
        "import math, gc, pandas as pd, numpy as np, psutil, torch, torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
        "                          GenerationConfig)\n",
        "from codecarbon import EmissionsTracker\n",
        "from contextlib import nullcontext\n",
        "from types import SimpleNamespace\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if device==\"cuda\":\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    vram_total_gb = torch.cuda.get_device_properties(0).total_memory/(1024**3)\n",
        "else:\n",
        "    gpu_name, vram_total_gb = \"CPU\", 0.0\n",
        "print(f\"Device: {device} | GPU: {gpu_name} | VRAM: {vram_total_gb:.1f} GB | Torch {torch.__version__} | Py {platform.python_version()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt_OgbcZ5byk",
        "outputId": "57406e52-1243-4a63-fecd-0961ae7d5408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda | GPU: NVIDIA A100-SXM4-40GB | VRAM: 39.6 GB | Torch 2.8.0+cu126 | Py 3.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== CodeCarbon Helpers (Berlin) =====================\n",
        "import os as _os, time as _time, inspect as _inspect\n",
        "\n",
        "_os.environ[\"CODECARBON_ALLOW_MULTIPLE_RUNS\"]=\"true\"\n",
        "USE_GCP_REGION=True; COUNTRY_ISO_CODE=\"DEU\"; CLOUD_PROVIDER=\"google\"; CLOUD_REGION=\"europe-west10\"\n",
        "\n",
        "def _trk_base():\n",
        "    base=dict(log_level=\"error\", output_dir=\".\")\n",
        "    sig=_inspect.signature(EmissionsTracker.__init__)\n",
        "    if \"measure_power_secs\" in sig.parameters: base[\"measure_power_secs\"]=1\n",
        "    if \"tracking_mode\" in sig.parameters:      base[\"tracking_mode\"]=\"process\"\n",
        "    if USE_GCP_REGION:\n",
        "        if \"cloud_provider\" in sig.parameters: base[\"cloud_provider\"]=CLOUD_PROVIDER\n",
        "        if \"cloud_region\" in sig.parameters:   base[\"cloud_region\"]=CLOUD_REGION\n",
        "        if \"country_iso_code\" in sig.parameters: base[\"country_iso_code\"]=COUNTRY_ISO_CODE\n",
        "    else:\n",
        "        if \"country_iso_code\" in sig.parameters: base[\"country_iso_code\"]=COUNTRY_ISO_CODE\n",
        "    return base\n",
        "\n",
        "def _tracker(name,out):\n",
        "    cache=f\"/content/.codecarbon_cache_{name}_{int(_time.time())}\"\n",
        "    _os.environ[\"CODECARBON_CACHE_DIR\"]=cache\n",
        "    for d in (_os.path.expanduser(\"~/.codecarbon\"), \"/content/.codecarbon\"):\n",
        "        lf=_os.path.join(d,\"codecarbon.lock\")\n",
        "        if _os.path.exists(lf):\n",
        "            try: _os.remove(lf)\n",
        "            except: pass\n",
        "    return EmissionsTracker(project_name=name, output_file=out, **_trk_base())\n",
        "\n",
        "def measure(phase, fn, prefix):\n",
        "    log=f\"{prefix}_{phase}.csv\"; tr=_tracker(f\"{prefix}_{phase}\",log)\n",
        "    started=False\n",
        "    try:\n",
        "        tr.start(); started=True\n",
        "    except Exception as e:\n",
        "        print(\"[CodeCarbon] Start-Fehler:\", e)\n",
        "    t0=_time.time(); res=fn(); t1=_time.time()\n",
        "    e = tr.stop() if started else None\n",
        "\n",
        "    def _up(e):\n",
        "        if e is None: return 0.0,0.0\n",
        "        if hasattr(e,\"energy_consumed\") and hasattr(e,\"emissions\"):\n",
        "            return float(e.energy_consumed), float(e.emissions)\n",
        "        if isinstance(e,dict):\n",
        "            return float(e.get(\"energy_consumed\",0.0)), float(e.get(\"emissions\", e.get(\"emissions_kg\",0.0)))\n",
        "        return 0.0,0.0\n",
        "\n",
        "    ekwh,co2=_up(e)\n",
        "    if ekwh==0.0 and _os.path.exists(log):\n",
        "        try:\n",
        "            df=pd.read_csv(log)\n",
        "            for c in [\"energy_consumed\",\"energy_consumed_kwh\",\"energy (kWh)\",\"energy_consumed (kWh)\"]:\n",
        "                if c in df.columns: ekwh=float(df[c].iloc[-1])\n",
        "        except: pass\n",
        "    return {\"phase\":phase,\"time_s\":t1-t0,\"energy_kwh\":ekwh,\"co2_kg\":co2}, res"
      ],
      "metadata": {
        "id": "fDnvWoIw5bu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Konfiguration =====================\n",
        "MODEL_ID     = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "ALIAS        = \"r1q15b\"\n",
        "PRUNE_AMOUNT = 0.20  # 20% global L1\n",
        "PRUNE_TARGETS = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"up_proj\",\"down_proj\",\"gate_proj\"]\n",
        "\n",
        "# Greedy-Generation ohne Sampling-Warnungen\n",
        "GC_GREEDY = GenerationConfig(\n",
        "    do_sample=False, temperature=None, top_p=None, top_k=None, num_beams=1\n",
        ")"
      ],
      "metadata": {
        "id": "xMSrkiLd5bfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Laden (CPU) & Pruning =====================\n",
        "def load_for_pruning_cpu(model_id:str):\n",
        "    tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "    if tok.pad_token_id is None: tok.pad_token = tok.eos_token\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id, device_map=None, torch_dtype=torch.float32, low_cpu_mem_usage=True\n",
        "    ).eval()\n",
        "    return tok, model\n",
        "\n",
        "def global_magnitude_prune(model, amount:float):\n",
        "    params=[]\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Linear) and any(tag in name for tag in PRUNE_TARGETS):\n",
        "            params.append((module, \"weight\"))\n",
        "    if not params:\n",
        "        print(\"[Pruning] Keine passenden Linear-Layer gefunden.\"); return 0.0\n",
        "    print(\"[Pruning] betroffene Linear-Layer:\", len(params))\n",
        "    fallback=False\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            prune.global_unstructured(params, pruning_method=prune.L1Unstructured, amount=amount)\n",
        "    except Exception as e:\n",
        "        print(\"[Pruning] global fehlgeschlagen, layer-weise:\", repr(e))\n",
        "        with torch.no_grad():\n",
        "            for m, n in params:\n",
        "                prune.l1_unstructured(m, n, amount=amount)\n",
        "        fallback=True\n",
        "\n",
        "    # Sparsity messen über Masken, dann remove()\n",
        "    total=zeros=0\n",
        "    for m,_ in params:\n",
        "        mask = dict(m.named_buffers()).get(\"weight_mask\", None)\n",
        "        if mask is not None:\n",
        "            zeros += int((mask == 0).sum().item())\n",
        "            total += mask.numel()\n",
        "        try: prune.remove(m,\"weight\")\n",
        "        except: pass\n",
        "    sp = (zeros/total) if total else 0.0\n",
        "    print(f\"[Pruning] fertig. Modus: {'layer-weise' if fallback else 'global'} | Sparsity ≈ {sp:.3f}\")\n",
        "    return sp"
      ],
      "metadata": {
        "id": "HWHIP2V35p9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Eval (gen/ppl/bleu) =====================\n",
        "bleu_metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def safe_max_len(tok, model, fallback=512, upper=100000):\n",
        "    cand=getattr(tok,\"model_max_length\",None)\n",
        "    if isinstance(cand,int) and 0<cand<upper: return min(cand,fallback)\n",
        "    cand=getattr(getattr(model,\"config\",None),\"max_position_embeddings\",None)\n",
        "    if isinstance(cand,int) and 0<cand<upper: return min(cand,fallback)\n",
        "    return fallback\n",
        "\n",
        "def eval_generate(tok, model, max_new_tokens=32):\n",
        "    prompts=[\n",
        "      \"List two advantages of pruning LLMs.\",\n",
        "      \"Explain global magnitude pruning in one paragraph.\",\n",
        "      \"Why does pruning help energy efficiency?\"\n",
        "    ]\n",
        "    ml=safe_max_len(tok, model); outs=[]; n_tok=0\n",
        "    with torch.no_grad():\n",
        "        for p in prompts:\n",
        "            enc=tok(p, return_tensors=\"pt\", truncation=True, max_length=ml).to(model.device)\n",
        "            room=ml-enc[\"input_ids\"].shape[1]; cur=max(1,min(max_new_tokens,int(room)))\n",
        "            out=model.generate(**enc, max_new_tokens=cur, generation_config=GC_GREEDY, pad_token_id=tok.eos_token_id)\n",
        "            n_tok+=int(out.shape[1]-enc[\"input_ids\"].shape[1])\n",
        "            outs.append(tok.decode(out[0], skip_special_tokens=True))\n",
        "    return outs, n_tok\n",
        "\n",
        "def eval_ppl(tok, model, split=\"test[:1%]\"):\n",
        "    ds=load_dataset(\"wikitext\",\"wikitext-2-raw-v1\", split=split)\n",
        "    ml=safe_max_len(tok, model); losses=[]\n",
        "    with torch.no_grad():\n",
        "        for t in ds[\"text\"]:\n",
        "            if not isinstance(t,str) or len(t.strip())<4: continue\n",
        "            enc=tok(t, return_tensors=\"pt\", truncation=True, max_length=ml)\n",
        "            ids=enc[\"input_ids\"].to(model.device)\n",
        "            out=model(ids, labels=ids)\n",
        "            losses.append(float(out.loss.detach().cpu()))\n",
        "    return math.exp(np.mean(losses)) if losses else None\n",
        "\n",
        "def eval_bleu(tok, model, split=\"test[:32]\", max_new_tokens=32):\n",
        "    ds=load_dataset(\"wmt14\",\"de-en\", split=split)\n",
        "    ml=safe_max_len(tok, model); preds, refs=[],[]\n",
        "    with torch.no_grad():\n",
        "        for ex in ds:\n",
        "            de, en = ex[\"translation\"][\"de\"], ex[\"translation\"][\"en\"]\n",
        "            prompt = f\"Translate to English:\\nGerman: {de}\\nEnglish:\"\n",
        "            enc=tok(prompt, return_tensors=\"pt\", truncation=True, max_length=ml).to(model.device)\n",
        "            room=ml-enc[\"input_ids\"].shape[1]; cur=max(1,min(max_new_tokens,int(room)))\n",
        "            out=model.generate(**enc, max_new_tokens=cur, generation_config=GC_GREEDY, pad_token_id=tok.eos_token_id)\n",
        "            gen=tok.decode(out[0], skip_special_tokens=True)\n",
        "            hyp=gen.split(\"English:\")[-1].strip().split(\"\\n\")[0].strip() or gen.strip()\n",
        "            preds.append(hyp); refs.append([en])\n",
        "    return float(bleu_metric.compute(predictions=preds, references=refs)[\"score\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8e260b81b4554c15a7c4f647d996d112",
            "d726dac979c04201aed654664160b81a",
            "c222cb8476364fa48bc5fd808c84e02d",
            "3029ae1ed9a14ed98f314774ac744fc0",
            "d755d1434f864eb1a630345e8b3356d1",
            "e9d05098695a4fcfb26e6af245b74716",
            "f78cbeb2a8fa43a488f4effed8c33ad3",
            "c27dc54746314a0b882e1e4954fb1462",
            "72346a9d264e4f85a10db154a25ec7df",
            "5f60b141f8b74261afbcff42a4816ca2",
            "fa4139de2dd9438fa61fb906dd2883ad"
          ]
        },
        "id": "yA9IUbTs5wb4",
        "outputId": "4b28ea94-5f9a-422b-86a7-bf28c3b12e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e260b81b4554c15a7c4f647d996d112"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Pipeline: prune → save → reload(int8) → eval =====================\n",
        "def run_once(model_id:str, alias=\"model\", prune_amount=PRUNE_AMOUNT):\n",
        "    print(f\"\\n### Starte Pruning ({int(prune_amount*100)}%): {alias} ({model_id})\")\n",
        "    tok_cpu, model_cpu = load_for_pruning_cpu(model_id)\n",
        "    prefix = f\"deepseek_pruning_{alias}\"\n",
        "\n",
        "    # Phasen: prune\n",
        "    m_prune, sparsity = measure(\"prune\", lambda: global_magnitude_prune(model_cpu, prune_amount), prefix)\n",
        "\n",
        "    # Speichern des pruned Modells\n",
        "    save_dir = os.path.join(project_path, f\"pruned_{int(prune_amount*100)}pct_tmp\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    model_cpu.save_pretrained(save_dir)\n",
        "    tok_cpu.save_pretrained(save_dir)\n",
        "    del model_cpu; gc.collect()\n",
        "\n",
        "    # Reload quantisiert (8-bit) für Eval\n",
        "    bnb8 = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    tok = AutoTokenizer.from_pretrained(save_dir, use_fast=True)\n",
        "    if tok.pad_token_id is None: tok.pad_token = tok.eos_token\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        save_dir, device_map=\"auto\", quantization_config=bnb8, attn_implementation=\"sdpa\"\n",
        "    ).eval()\n",
        "\n",
        "    # Phasen: gen / ppl / bleu\n",
        "    m_gen,  (samples, n_tok) = measure(\"gen\",  lambda: eval_generate(tok, model, 32), prefix)\n",
        "    m_ppl,  ppl_val          = measure(\"ppl\",  lambda: eval_ppl(tok, model, \"test[:1%]\"), prefix)\n",
        "    if device==\"cuda\": torch.cuda.empty_cache()\n",
        "    m_bleu, bleu_val         = measure(\"bleu\", lambda: eval_bleu(tok, model, \"test[:32]\", 32), prefix)\n",
        "\n",
        "    # Speicherstände\n",
        "    ram  = psutil.Process().memory_info().rss/(1024**3)\n",
        "    valloc= torch.cuda.memory_allocated()/(1024**3) if device==\"cuda\" else 0.0\n",
        "    vres = torch.cuda.memory_reserved() /(1024**3) if device==\"cuda\" else 0.0\n",
        "\n",
        "    row = dict(model_id=model_id, alias=alias, precision=\"int8 (pruned)\",\n",
        "               time_s=m_prune[\"time_s\"]+m_gen[\"time_s\"]+m_ppl[\"time_s\"]+m_bleu[\"time_s\"],\n",
        "               energy_kwh=m_prune[\"energy_kwh\"]+m_gen[\"energy_kwh\"]+m_ppl[\"energy_kwh\"]+m_bleu[\"energy_kwh\"],\n",
        "               co2_kg=m_prune[\"co2_kg\"]+m_gen[\"co2_kg\"]+m_ppl[\"co2_kg\"]+m_bleu[\"co2_kg\"],\n",
        "               tokens_out=int(n_tok), ppl=ppl_val, bleu=bleu_val, sparsity=sparsity,\n",
        "               ram_GB=ram, vram_alloc_GB=valloc, vram_reserved_GB=vres,\n",
        "               notes=f\"GPU={gpu_name}, VRAM={vram_total_gb:.1f} GB\")\n",
        "    phases = pd.DataFrame([\n",
        "        {**m_prune, \"phase\":\"prune\"},\n",
        "        {**m_gen,   \"phase\":\"gen\"},\n",
        "        {**m_ppl,   \"phase\":\"ppl\"},\n",
        "        {**m_bleu,  \"phase\":\"bleu\"},\n",
        "    ])\n",
        "\n",
        "    # Samples speichern\n",
        "    with open(\"deepseek_pruning_samples.txt\",\"w\",encoding=\"utf-8\") as f:\n",
        "        for i,txt in enumerate(samples,1): f.write(f\"--- Beispiel {i} ---\\n{txt}\\n\\n\")\n",
        "\n",
        "    return row, phases"
      ],
      "metadata": {
        "id": "uMZp_BlJ50pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Ausführen & Speichern =====================\n",
        "row, phases = run_once(MODEL_ID, alias=ALIAS, prune_amount=PRUNE_AMOUNT)\n",
        "df  = pd.DataFrame([row])\n",
        "df[\"kg_per_kwh\"]=(df[\"co2_kg\"]/df[\"energy_kwh\"]).replace([np.inf,-np.inf],np.nan)\n",
        "\n",
        "df.to_csv(\"deepseek_pruning_results.csv\", index=False)\n",
        "phases.to_csv(\"deepseek_pruning_per_phase.csv\", index=False)\n",
        "\n",
        "print(\"Gespeichert:\")\n",
        "print(\" - deepseek_pruning_results.csv\")\n",
        "print(\" - deepseek_pruning_per_phase.csv\")\n",
        "print(\" - deepseek_pruning_samples.txt\")\n",
        "\n",
        "from IPython.display import display\n",
        "display(df); display(phases)\n",
        "\n",
        "print(\"\\nKurzer Zusammenfassungsauszug:\")\n",
        "print(df[[\"sparsity\",\"ppl\",\"bleu\",\"tokens_out\",\"energy_kwh\",\"co2_kg\",\"time_s\"]].to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "51840788c20945e68bd0a41d41053b16",
            "df63f1dbd9e441a6bf9535134a1b525e",
            "1e98cded72264a02b2ae309ce6af8810",
            "0e136077bd3e4453a559200dfba3d689",
            "5fe14ef11da8438fa292193af3185415",
            "d98412c477ed48b5b55f3a0f0ef90b51",
            "c12c4c6cddc948f89e09deb73cc1b5fd",
            "7cefca81ad0743b69ca9bad7f1d9fcee",
            "f011975d748b4302a67073a45cd37496",
            "56cfec328d744b04ad0548ce0b43b0ae",
            "74600bd9cfe34ce3ab5f64d4b2c8e7fa",
            "6aed61d37d38440e8482ef1f51f2e5d5",
            "d79f39f2590b43c7afd824a1d010069c",
            "a005cc603cbd4718b133786d91b9845a",
            "b3c746ba2d4a4f20a89b885376bc3f84",
            "436f67c2f34f402884cf1e44b5b703e3",
            "02204493a5744b289a288c42659b45ef",
            "c43251dc3545452d9f66a29dda3df6e1",
            "7239f8b9d137425abc4fd500745b4eae",
            "e6057fffef8d4e538caf39e8a7f0d3cd",
            "13bd8e1d167b4b178dba36a4d6cabd0a",
            "5e8dc3470ef142f1bfbd4244797d6447",
            "88c98f85d3f0421ebda6d628ce5d5797",
            "390e80787c9545a8b785a77aba54026a",
            "3ed9b0f08b204fb2b94ffb0cbf11e62a",
            "5df61ce60e3b46bab27c08ebb19fcb5d",
            "c6c4525fa3c44a1484e07bd7f8114d85",
            "19fade3e56924adc96d3b027c8c715fd",
            "5042fb02d0564d988b509b6391a3d810",
            "8161b241551b47008fe7df7b12eb1510",
            "787493f193ee476d90f65c0c02d0b2fb",
            "f86e67765eb44c368fe445d1762be78f",
            "8cdbc307cf8641e293902e88a54f138e",
            "3a0c4159f3284a2e83720105403b4de1",
            "9a5a91eb435048998c57c7fb708bbd14",
            "e89d18be36984b90b999aec6975e3d52",
            "49cf72db1f4e4fac8d59d1f66899a20b",
            "d92b7d7fc70b427a9d2b495d06efc1ec",
            "40139fa210214bf39f0578a3c4bb0355",
            "a05741a306fe4a40b96c5fccd2e07364",
            "8fe99fdff67b4a17ab48aeec9f99adc8",
            "573d2523bbbc46c3b93aefb7e83e1296",
            "09f70eb36c2e4f659040aae52e2c8cb6",
            "662e4e3be36146229a7a38ea1de24a93",
            "df878634f93b40c1974f92954410daa3",
            "3216f9ea003945dd832165f48b5c672a",
            "8bd79aa94ad744f2bcb627983b1a20dc",
            "c1c0a1e73e764261984840f1e285603f",
            "51532c11cec249d593b3b6f5f062c535",
            "c01ce4ca0f20455f8b58b1f292baa43f",
            "24314dedfb76432e98ca2c46b61924c8",
            "f5b1c42e3e7942cbb0f7156fc7250b23",
            "0b858fe8007b4dcc9709543669894257",
            "0deda06a6d3948a6ae715d78e28da715",
            "222804f2801044e385538cecc43dd143",
            "80072ef235904fa087722028d0e4a649",
            "12b581f0064d442b9ae28a340a92f7cc",
            "a7380adf7cee40b6b8ef43499af29bfe",
            "9f4c092d57954e7baf1d1f10465d5057",
            "5f9f8c6bc2b64b0c9135a4c3e3fc4c0a",
            "d4ae159157144df281d63b9fbc79031d",
            "7d2307ec2a64419db3fe3c72a6c2deb1",
            "b7c314160a9740b4972dbe460bb81936",
            "6e666b56740749f6b4fe823d87c999f9",
            "897b59b4d299453196ba4b4e417b1a4d",
            "a33d753ace4f4bb0af19ca0160078262",
            "3b35d9afacc846ffa47ecc7f6481e0fd",
            "a0bd81233f894eedb253b31bc6a45839",
            "a483cea72ab14481b4a1cb24935b8c87",
            "b63d67b97ad6458a978fc4a5f426ccac",
            "25245415f623408983a0fb4d07398a74",
            "9765bd6e82a64fae810bfbe10ffcbab0",
            "397cd5d6fb9c44cb994f2be9888ddd81",
            "48e5307d53bd429c8a3d34ab3d8a4acb",
            "5022be22835a4d85a9b4da0235524020",
            "987bc096aaa14834ba29aca01a304a1b",
            "f556df4cc1204352aa75faaa7fbb6920",
            "33e6f01cd30549dcb339149284e78c4c",
            "a08dadcc25bc4ae7afbb8a30486eee18",
            "6d3cf561825b4b2fb66c2533f24469ad",
            "03df6d2ff2e0476a9daa1921151766f7",
            "d80ed89868ff4f95859482115b9fb88f",
            "31407a1011f749209154fde8fdcbe49e",
            "4f5db7fdf4a446f882d5e13058030737",
            "a7887437209542198d669939e64ff088",
            "2700714169e7410a8c8490f11c829755",
            "f52ca195a6204822907ed2f82c9dfa8b",
            "ab540d22203c45c3a9c416eb274dec3a",
            "9cc39db54e674133a672ce019aefaaa0",
            "7006035554f74b269604ff57700b1f0b",
            "523094ac2a1d46a88cd776c55093dbe0",
            "12a700e68a2d4f8687e51fb939412395",
            "706a0bdb456e4dfe9466c8ac0baf51e2",
            "1352351d86194c12ad766b890f4fec2a",
            "f52b2691b167402a9fd7c745a803c1a7",
            "b6cd415b5e724c869187fff73ebd8041",
            "6f9174d752094e71976845873c2687ae",
            "91896073f5b24747aa526f792def5bdd",
            "2dbfd5e771f745c98848e0acdb10f509",
            "03575b9f0bcd4e2589913cd1904e0338",
            "d4e1f4debe0e4fe482600cc2cfb98080",
            "a053d20bb7b34799ac4fcc295d8eec2c",
            "3d2f35fe6a8f466fab841910fccf0269",
            "1754c2be33654457ba371f5a15254b54",
            "656d746d8a534ec38e0c749cf5f2b8ab",
            "769ac1e0cee740a18b406b5f2fdc63c8",
            "29e5eef039544d039c82d0cad53f072e",
            "d4577f98779045ddab7c805f283afb69",
            "689267e44e8040e58c5cf2c29c196068",
            "1a53f2504c5a4f0c9cad5dda8b83b415",
            "ee59521436544862936ef8dbe92855c5",
            "10b9f8165f574ad58dcbe7df69160544",
            "f6b28fd475974dbfa4c3555cc1f09fb0",
            "69eeea058075410d9dce22e98dac872b",
            "4fcf80aa3b5e45aa8310c24ee59b62b1",
            "c3c9eb09ce0746f088dea71a3e6774fa",
            "04cb4dc4095e401dbfdb21cfc9cb5d3d",
            "9e089882cfd245f296bd7d65f6b3a837",
            "9e6a444281204ebbb87353ad988e12bf",
            "285c9a05851545449ffac8232055a0d9",
            "5e61d82d188d4fcdb2faf563bf324f34",
            "3ee5bc4051a14775b4a1866defeb9f5c",
            "93928958553e48e581da116d50c7a66a",
            "d3c46a13f9d445c1ad32abb03b5453a4",
            "65a23b3c0da24b9ca29fffaead38b7ae",
            "b94aa896b4f24a26b7b897edd9208264",
            "1c9c882ac5994663b36ec5098f6d3262",
            "b4e5bb02221048d18bc59710140005db",
            "035624f8673b4e99abf848670c4e5092",
            "bb45f5cec96749159406f3fc80b36098",
            "3d28b0d03ba044a681a78d275e6a816f",
            "ae3c87f1863d408099bb35b6c5a0fba5",
            "8d1f494788c44d5e8b80bfaa88d80716",
            "0a7f8a7e6c524b588821e77502ea84ea",
            "66c36e4ff5cf4060a93387e4a6408839",
            "69802939a3a24b7bbdf4621fd8ec8e16",
            "ab57d547a0c043af86aeb1bbb866d878",
            "2df808f1de2a408ea602870cd44a6d9b",
            "1a5e1bd3293f4391ae332e4649cf414c",
            "0a10b9e9cb2f4b7aa86135577b80087c",
            "d0949c5595aa4e9381665f1c1fee3c11",
            "3bf6dc9000244a30bfaebcdf80dd0819",
            "be51f74dced441ffa67203931a6639bb",
            "5bb36f936c284b0d88e4c374436a9241",
            "d13064c2008a4a3f80c217fb60b696f3",
            "24382dee361b4063af62b813a1821a32",
            "6aca4e101d394a43b85293f645ac9df2",
            "7bc7cf4760fb4258930199370c99ce4f",
            "9a37e8d7a3ac42a482e4d29e6cc60141",
            "60f29c76eded4399b4e0cd8de504311e",
            "ce6f2e26fbc04c7c8197363e56510b07",
            "95d253799438440c8886c8d5159c1d44",
            "cba2fb1812a14cbe95359db5b2bedd97",
            "a8df9a4a0afe461190c9b84462aa2b21",
            "73391f4de8524521a6244e061dd8db55",
            "f50b6769758842199632df17cfc20f71",
            "0c7f5fdd0e474e51bac1dbe36d12afcc",
            "d9fadf4ae7d74100bdb791a7357c195a",
            "30b8efa78b6c412589a9e736d007247e",
            "393b6a70c61c445e8e7d150e01c5c5f8",
            "9724d6c4cae44e0998cdb787c24f24a8",
            "4d282730866e43bca2d4bf2a38749fc2",
            "56aa25cd3b4d47c3a8af683fa0b7afb1",
            "ed7c2def42cd401cbd1e0c17f3671b7f",
            "439cf367e0fe40ba912633c86410cea7",
            "527d5230cd8943a493b1baeca2c2c490",
            "4b0c0fdf483e469b85ad1a846474be0d",
            "0cfb1252f78e403d92584289908f36da",
            "7c8bf28d13a841c58c4dc720c45697d7",
            "a20c7a2c2f124149831f777866628807",
            "a59cb05355214aba97807ebb67b73362",
            "a4f54c1b65f84fedb4cd8fa206119984",
            "a412bfc17666415fb6b5fb2e80481c79",
            "eb1eb4f55bc44e84a19528fbc1800710",
            "850e6e80a5e14a2cb0119e0e84c774ab",
            "1afa6fc5fafc4c4abc8602400f855e86",
            "93ecbb034fe743b398eef5ad53fd9ad6",
            "d644ccefdf0a45a98a28c3717ff9c65a",
            "3992b3262c88476dac57b58fe487cbc3",
            "8f7700e6400448f9952fd0a21ad28836",
            "0bc0a7a0f32c4fc494f958af73f8d01b",
            "9eb27a8f3d52420b8b9e7713b68a4afe",
            "300fedad89e64b54871a0b53f330692d",
            "016f327dde0e488cbf12185de9499a7a",
            "751230463ded4990b30699a821448f7e",
            "737d6b60f43b4db2a87fa6f3800f2847",
            "c4d4cf1e02f7491bb5b3c47ce92d599d",
            "6516fa8fb001408bbcee575b77eaa281",
            "9404e617c5934195a448af4e96c1c9bf",
            "1e9970d4b44848a0b185a4a78d830616",
            "f5b2a5d8c07f455794b5c388aab0c5dd",
            "f626631240254217b8ca76c1a47a91c5",
            "ee061934957b404997468376e1733616",
            "004c5a0bd4b64acfab6fb6cbb6adc45a",
            "4a2a1ce2c13c4f578e837a042dbbbae1",
            "b95ed3de527c435ea8c5e5864a4f70bb",
            "3fe6eb5953ff491f9d19560eabf07152",
            "f84e05357687475ebc76ed82de8aafb2",
            "2869d24566d84ad8b680a3f478122415",
            "78f23fbb700e4223a3e3dbe78954f6ac",
            "c7fd843b79f04af9a34141d537f393ad",
            "2576432131694c58847a1cbee2e4592a",
            "8d217ce5d7744ee3b97e9eaf5ea07224",
            "3cae5111771b420186a581585c67adcb",
            "779da09198814617a6439d24b09108dd",
            "bdc72299a80e4d3982b429056e973c8c",
            "aa45f51517f546daacad6677b0dfc9df",
            "dcb1878a144d4b12b4c5ec85b83f98a8",
            "e30600d9e6324d6b96e153a26942cd3f",
            "807623fecae8494fa0393aef5fee8f5d",
            "634cd2c759714538897949e4a3d61e42",
            "695c5d2e29564dea8dba70086bf00240",
            "7b89822c29b94c2bb285a8b4d3e9dc7a",
            "eaf3d6dc5ead4bbfbd34c96cc4d952c9",
            "97180d00f02147afb0d6d8731704c63e",
            "adb0757ba2334042a79c85112a104266",
            "2d13de9e84d044a1a4befb013657fa01",
            "2bd9d4f86a1c4473a39a65250de5393d",
            "ed1026a3e1c14545a3d6645b3a70c421",
            "263eccee88df460f855def2d191044a1",
            "5278d075d79e4851b737b6e71dc9688a",
            "ee43cffd1d0e48cf8a410c6f1c91b5a9",
            "4d0e7d04e5204221a915e1dddd1a9293",
            "e5e73ab5f35f4094991b4a3533567a57",
            "8ec31d5347e6424aa8a032fd2054b2d9",
            "5067bfc9360d4d689ae923a00fca3c15",
            "48c2f85a6cc3448b965239f5ba1d9474",
            "1501fb47635c458bab4e602780650d9e",
            "5e4cd64c9b644cbd8f4fe72626324ef6",
            "0c1f0f61971c415b858ba0c57986e99a",
            "12a89f0678fa4bd98413705431b91dc5",
            "cb48d19d50664b429f2fa600e108d997",
            "66c342e837d74a76a121acfb42114da0",
            "54c9aff565ca42b39c934e897bf4a26d",
            "e5c5ad4c125b4de198a13fdf214cf519",
            "6b46d90d976642a09ac84f080da79a25",
            "befeca5129584502b693bed882d396a8",
            "746af5c6c4614df2990b1df6e8ae1322",
            "48a00e64922f463c897bda01bb91519c",
            "14e72e8a23c34d92bab15fb472ec8c32",
            "6049242729fc462b9ca3ab7f21994a38",
            "757a34e07998438cb7cedae193811dc2"
          ]
        },
        "id": "F_ZakTCx50lU",
        "outputId": "6cf7e27e-5962-40d9-d1eb-20ae1cc234a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Starte Pruning (20%): r1q15b (deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51840788c20945e68bd0a41d41053b16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aed61d37d38440e8482ef1f51f2e5d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c98f85d3f0421ebda6d628ce5d5797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a0c4159f3284a2e83720105403b4de1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df878634f93b40c1974f92954410daa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon WARNING @ 07:12:10] Multiple instances of codecarbon are allowed to run at the same time.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pruning] betroffene Linear-Layer: 196\n",
            "[Pruning] fertig. Modus: global | Sparsity ≈ 0.200\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80072ef235904fa087722028d0e4a649"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True, 'bos_token_id': 151646, 'eos_token_id': 151643}. If this is not desired, please set these values explicitly.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b35d9afacc846ffa47ecc7f6481e0fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikitext-2-raw-v1/test-00000-of-00001.pa(…):   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33e6f01cd30549dcb339149284e78c4c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikitext-2-raw-v1/train-00000-of-00001.p(…):   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cc39db54e674133a672ce019aefaaa0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikitext-2-raw-v1/validation-00000-of-00(…):   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03575b9f0bcd4e2589913cd1904e0338"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee59521436544862936ef8dbe92855c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ee5bc4051a14775b4a1866defeb9f5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d1f494788c44d5e8b80bfaa88d80716"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bb36f936c284b0d88e4c374436a9241"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/train-00000-of-00003.parquet:   0%|          | 0.00/280M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73391f4de8524521a6244e061dd8db55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/train-00001-of-00003.parquet:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "527d5230cd8943a493b1baeca2c2c490"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/train-00002-of-00003.parquet:   0%|          | 0.00/273M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93ecbb034fe743b398eef5ad53fd9ad6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/validation-00000-of-00001.parquet:   0%|          | 0.00/474k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6516fa8fb001408bbcee575b77eaa281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de-en/test-00000-of-00001.parquet:   0%|          | 0.00/509k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2869d24566d84ad8b680a3f478122415"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4508785 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "807623fecae8494fa0393aef5fee8f5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5278d075d79e4851b737b6e71dc9688a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3003 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb48d19d50664b429f2fa600e108d997"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gespeichert:\n",
            " - deepseek_pruning_results.csv\n",
            " - deepseek_pruning_per_phase.csv\n",
            " - deepseek_pruning_samples.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                    model_id   alias      precision  \\\n",
              "0  deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B  r1q15b  int8 (pruned)   \n",
              "\n",
              "       time_s  energy_kwh  co2_kg  tokens_out         ppl      bleu  sparsity  \\\n",
              "0  254.536563    0.007069     0.0          96  228.529511  5.439031       0.2   \n",
              "\n",
              "     ram_GB  vram_alloc_GB  vram_reserved_GB  \\\n",
              "0  4.611973       2.101943          2.828125   \n",
              "\n",
              "                                     notes  kg_per_kwh  \n",
              "0  GPU=NVIDIA A100-SXM4-40GB, VRAM=39.6 GB         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f7ecdfb-1117-4ff1-8bfe-4b366092fa92\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_id</th>\n",
              "      <th>alias</th>\n",
              "      <th>precision</th>\n",
              "      <th>time_s</th>\n",
              "      <th>energy_kwh</th>\n",
              "      <th>co2_kg</th>\n",
              "      <th>tokens_out</th>\n",
              "      <th>ppl</th>\n",
              "      <th>bleu</th>\n",
              "      <th>sparsity</th>\n",
              "      <th>ram_GB</th>\n",
              "      <th>vram_alloc_GB</th>\n",
              "      <th>vram_reserved_GB</th>\n",
              "      <th>notes</th>\n",
              "      <th>kg_per_kwh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B</td>\n",
              "      <td>r1q15b</td>\n",
              "      <td>int8 (pruned)</td>\n",
              "      <td>254.536563</td>\n",
              "      <td>0.007069</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96</td>\n",
              "      <td>228.529511</td>\n",
              "      <td>5.439031</td>\n",
              "      <td>0.2</td>\n",
              "      <td>4.611973</td>\n",
              "      <td>2.101943</td>\n",
              "      <td>2.828125</td>\n",
              "      <td>GPU=NVIDIA A100-SXM4-40GB, VRAM=39.6 GB</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f7ecdfb-1117-4ff1-8bfe-4b366092fa92')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f7ecdfb-1117-4ff1-8bfe-4b366092fa92 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f7ecdfb-1117-4ff1-8bfe-4b366092fa92');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_21e4d714-6401-417a-8f2c-ffa3a4a48afd\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_21e4d714-6401-417a-8f2c-ffa3a4a48afd button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alias\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"r1q15b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"int8 (pruned)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 254.53656339645386,\n        \"max\": 254.53656339645386,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          254.53656339645386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0070688536320938,\n        \"max\": 0.0070688536320938,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0070688536320938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"co2_kg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens_out\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 96,\n        \"max\": 96,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ppl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 228.52951087041473,\n        \"max\": 228.52951087041473,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          228.52951087041473\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5.439031139894533,\n        \"max\": 5.439031139894533,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.439031139894533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sparsity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1999999996947021,\n        \"max\": 0.1999999996947021,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1999999996947021\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ram_GB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.611972808837891,\n        \"max\": 4.611972808837891,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.611972808837891\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vram_alloc_GB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.101942539215088,\n        \"max\": 2.101942539215088,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.101942539215088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vram_reserved_GB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 2.828125,\n        \"max\": 2.828125,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2.828125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"GPU=NVIDIA A100-SXM4-40GB, VRAM=39.6 GB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kg_per_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   phase      time_s  energy_kwh  co2_kg\n",
              "0  prune   74.811190    0.002176     0.0\n",
              "1    gen   16.775126    0.000455     0.0\n",
              "2    ppl    9.360241    0.000253     0.0\n",
              "3   bleu  153.590006    0.004185     0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d1f3a21-c8d0-4e6f-9037-b044620c2c7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phase</th>\n",
              "      <th>time_s</th>\n",
              "      <th>energy_kwh</th>\n",
              "      <th>co2_kg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>prune</td>\n",
              "      <td>74.811190</td>\n",
              "      <td>0.002176</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gen</td>\n",
              "      <td>16.775126</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ppl</td>\n",
              "      <td>9.360241</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bleu</td>\n",
              "      <td>153.590006</td>\n",
              "      <td>0.004185</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d1f3a21-c8d0-4e6f-9037-b044620c2c7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d1f3a21-c8d0-4e6f-9037-b044620c2c7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d1f3a21-c8d0-4e6f-9037-b044620c2c7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5fab8fd5-2080-48b9-ab54-1bb37016fb51\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fab8fd5-2080-48b9-ab54-1bb37016fb51')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5fab8fd5-2080-48b9-ab54-1bb37016fb51 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8d10879b-4a05-498a-84f1-2d2c2cb1dde9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('phases')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8d10879b-4a05-498a-84f1-2d2c2cb1dde9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('phases');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "phases",
              "summary": "{\n  \"name\": \"phases\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"phase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"gen\",\n          \"bleu\",\n          \"prune\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_s\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66.72932308768769,\n        \"min\": 9.360241174697876,\n        \"max\": 153.59000635147095,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          16.77512550354004,\n          153.59000635147095,\n          74.811190366745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"energy_kwh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018282269953414259,\n        \"min\": 0.0002528358323004,\n        \"max\": 0.0041847334149397,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0004549255467526,\n          0.0041847334149397,\n          0.0021763588381011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"co2_kg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kurzer Zusammenfassungsauszug:\n",
            " sparsity        ppl     bleu  tokens_out  energy_kwh  co2_kg     time_s\n",
            "      0.2 228.529511 5.439031          96    0.007069     0.0 254.536563\n"
          ]
        }
      ]
    }
  ]
}